#!/usr/bin/env python3
"""
è¯•å·è§£ææ¨¡å—
è¯†åˆ«è¯•å·ç»“æ„ï¼ˆå·ã€é¢˜å‹ï¼‰å¹¶æå–é¢˜ç›®
"""
import re
import logging
from typing import List, Dict

from config import ETLConfig


class ExamParser:
    """è¯•å·è§£æå™¨"""

    def __init__(self, config: ETLConfig):
        self.config = config
        self.logger = self._setup_logger()

        # ç¼–è¯‘æ­£åˆ™æ¨¡å¼
        self.paper_pattern = re.compile(config.PAPER_PATTERN)
        self.type_pattern = re.compile(config.TYPE_PATTERN)

        # OCRå‹å¥½çš„æ­£åˆ™æ¨¡å¼ï¼ˆæ›´å®½æ¾ï¼‰
        self.ocr_question_patterns = [
            re.compile(p) for p in config.OCR_QUESTION_PATTERNS
        ]

    def _setup_logger(self) -> logging.Logger:
        """è®¾ç½®æ—¥å¿—"""
        logger = logging.getLogger(self.__class__.__name__)
        logger.setLevel(getattr(logging, self.config.log_level))
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter('%(levelname)s: %(message)s')
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        return logger

    def identify_sections(self, pages_text: List[Dict]) -> List[Dict]:
        """
        è¯†åˆ«è¯•å·å„éƒ¨åˆ†ï¼ˆå·ã€é¢˜å‹ï¼‰

        Args:
            pages_text: é¡µé¢æ–‡æœ¬åˆ—è¡¨ï¼ŒåŒ…å«sourceæ ‡è®°

        Returns:
            List[Dict]: è¯†åˆ«å‡ºçš„éƒ¨åˆ†åˆ—è¡¨ï¼ŒåŒ…å«sourceæ ‡è®°
        """
        print("\nğŸ“‹ æ­¥éª¤2: è¯†åˆ«è¯•å·ç»“æ„...")

        sections = []
        current_paper = None
        current_type = None
        current_content = []
        current_source = 'pdfplumber'  # è·Ÿè¸ªå½“å‰å†…å®¹çš„æ¥æº

        for page in pages_text:
            lines = page['text'].split('\n')
            # è®°å½•æ­¤é¡µçš„æ¥æº
            page_source = page.get('source', 'pdfplumber')

            for line in lines:
                line = line.strip()
                if not line:
                    continue

                # æ£€æµ‹æ˜¯å¦æ˜¯æ–°çš„"å·"
                paper_match = self.paper_pattern.search(line)
                if paper_match and line.startswith('å·'):
                    # ä¿å­˜ä¹‹å‰çš„section
                    if current_paper and current_content:
                        sections.append({
                            'paper': current_paper,
                            'type': current_type or 'Unknown',
                            'content': '\n'.join(current_content),
                            'source': current_source
                        })

                    current_paper = f"å·{paper_match.group(1)}"
                    current_type = None
                    current_content = []
                    current_source = page_source
                    continue

                # æ£€æµ‹æ˜¯å¦æ˜¯æ–°çš„é¢˜å‹
                type_match = self.type_pattern.match(line)
                if type_match:
                    # ä¿å­˜ä¹‹å‰çš„section
                    if current_paper and current_content:
                        sections.append({
                            'paper': current_paper,
                            'type': current_type or 'Unknown',
                            'content': '\n'.join(current_content),
                            'source': current_source
                        })

                    current_type = type_match.group(1)
                    current_content = []
                    current_source = page_source
                    continue

                # æ”¶é›†é¢˜ç›®å†…å®¹
                if current_paper:
                    current_content.append(line)

        # ä¿å­˜æœ€åä¸€ä¸ªsection
        if current_paper and current_content:
            sections.append({
                'paper': current_paper,
                'type': current_type or 'Unknown',
                'content': '\n'.join(current_content),
                'source': current_source
            })

        # æ‰“å°è¯†åˆ«ç»“æœ
        paper_section_count = {}
        for sec in sections:
            if sec['paper'] not in paper_section_count:
                paper_section_count[sec['paper']] = 0
            paper_section_count[sec['paper']] += 1

        for paper, count in sorted(paper_section_count.items()):
            print(f"   {paper}: {count} ä¸ªé¢˜å‹éƒ¨åˆ†")

        return sections

    def extract_questions_from_section(self, section: Dict) -> List[Dict]:
        """
        ä»sectionä¸­æå–é¢˜ç›®ï¼ˆæ”¯æŒOCRå®¹é”™ï¼‰

        Args:
            section: è¯•å·éƒ¨åˆ†ï¼ŒåŒ…å«sourceæ ‡è®°

        Returns:
            List[Dict]: é¢˜ç›®åˆ—è¡¨
        """
        questions = []
        content = section['content']

        # æ£€æµ‹æ˜¯å¦ä¸ºOCRæ–‡æœ¬
        is_ocr_text = section.get('source') == 'ocr'

        # é€‰æ‹©åˆé€‚çš„æ­£åˆ™æ¨¡å¼
        patterns_to_use = self.config.QUESTION_PATTERNS
        if is_ocr_text:
            # OCRæ–‡æœ¬ï¼šå…ˆå°è¯•OCRä¸“ç”¨æ¨¡å¼ï¼Œå†å°è¯•å¸¸è§„æ¨¡å¼
            patterns_to_use = self.config.OCR_QUESTION_PATTERNS + self.config.QUESTION_PATTERNS

        for pattern in patterns_to_use:
            matches = re.finditer(pattern, content, re.MULTILINE)

            for match in matches:
                q_num = match.group(1)
                q_content = match.group(2).strip()

                # OCRå®¹é”™å¤„ç†
                if is_ocr_text:
                    q_content = self._clean_ocr_content(q_content)

                # æ¸…ç†å†…å®¹
                q_content = re.sub(r'\s+', ' ', q_content)
                q_content = q_content.strip()

                # è¿‡æ»¤å¤ªçŸ­æˆ–æ— æ•ˆå†…å®¹
                if len(q_content) < self.config.min_content_length:
                    continue

                # è¿‡æ»¤çº¯æ•°å­—æˆ–å­—æ¯
                if re.match(r'^[\dA-D\s()]+$', q_content):
                    continue

                questions.append({
                    'Paper_ID': section['paper'],
                    'Question_Type': section['type'],
                    'Question_Number': q_num,
                    'Content': q_content[:self.config.max_content_length]
                })

            if questions:
                break

        return questions

    def _clean_ocr_content(self, content: str) -> str:
        """
        æ¸…ç†OCRè¯†åˆ«çš„é¢˜ç›®å†…å®¹ï¼Œä¿®æ­£å¸¸è§OCRé”™è¯¯

        Args:
            content: OCRè¯†åˆ«çš„å†…å®¹

        Returns:
            str: æ¸…ç†åçš„å†…å®¹
        """
        if not content:
            return content

        # å¸¸è§OCRé”™è¯¯ä¿®æ­£
        corrections = {
            'O ': '0 ',  # é¢˜å·ä¸­çš„Oå¯èƒ½æ˜¯0
            ' l ': ' 1 ',  # é€‰é¡¹ä¸­çš„lå¯èƒ½æ˜¯1
            'â‘´': '(1)',
            'â‘µ': '(2)',
            'â‘¶': '(3)',
            'â‘·': '(4)',
            'â‘¸': '(5)',
            'â‘¹': '(6)',
            'â‘º': '(7)',
            'â‘»': '(8)',
            'â‘¼': '(9)',
            'â‘½': '(10)',
            'â‘ ': '(1)',
            'â‘¡': '(2)',
            'â‘¢': '(3)',
            'â‘£': '(4)',
            'â‘¤': '(5)',
        }

        for wrong, correct in corrections.items():
            content = content.replace(wrong, correct)

        return content

    def extract_questions(self, sections: List[Dict]) -> List[Dict]:
        """
        ä»æ‰€æœ‰éƒ¨åˆ†æå–é¢˜ç›®

        Args:
            sections: è¯•å·éƒ¨åˆ†åˆ—è¡¨

        Returns:
            List[Dict]: æ‰€æœ‰é¢˜ç›®åˆ—è¡¨
        """
        print("\nğŸ·ï¸  æ­¥éª¤3: æå–é¢˜ç›®...")

        all_questions = []
        for section in sections:
            questions = self.extract_questions_from_section(section)
            all_questions.extend(questions)

        print(f"   âœ… å…±æå– {len(all_questions)} é“é¢˜ç›®")

        # æŒ‰åˆ†å·ç»Ÿè®¡
        paper_stats = {}
        for q in all_questions:
            p = q['Paper_ID']
            paper_stats[p] = paper_stats.get(p, 0) + 1

        print(f"\n   å„åˆ†å·é¢˜ç›®æ•°:")
        for paper, count in sorted(paper_stats.items()):
            print(f"      {paper}: {count} é“")

        return all_questions
