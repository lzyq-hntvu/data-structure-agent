#!/usr/bin/env python3
"""
è¯•å·è§£ææ¨¡å—
è¯†åˆ«è¯•å·ç»“æ„ï¼ˆå·ã€é¢˜å‹ï¼‰å¹¶æå–é¢˜ç›®
"""
import re
import logging
from typing import List, Dict

from config import ETLConfig


class ExamParser:
    """è¯•å·è§£æå™¨"""

    def __init__(self, config: ETLConfig):
        self.config = config
        self.logger = self._setup_logger()

        # ç¼–è¯‘æ­£åˆ™æ¨¡å¼
        self.paper_pattern = re.compile(config.PAPER_PATTERN)
        self.type_pattern = re.compile(config.TYPE_PATTERN)

    def _setup_logger(self) -> logging.Logger:
        """è®¾ç½®æ—¥å¿—"""
        logger = logging.getLogger(self.__class__.__name__)
        logger.setLevel(getattr(logging, self.config.log_level))
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter('%(levelname)s: %(message)s')
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        return logger

    def identify_sections(self, pages_text: List[Dict]) -> List[Dict]:
        """
        è¯†åˆ«è¯•å·å„éƒ¨åˆ†ï¼ˆå·ã€é¢˜å‹ï¼‰

        Args:
            pages_text: é¡µé¢æ–‡æœ¬åˆ—è¡¨

        Returns:
            List[Dict]: è¯†åˆ«å‡ºçš„éƒ¨åˆ†åˆ—è¡¨
        """
        print("\nğŸ“‹ æ­¥éª¤2: è¯†åˆ«è¯•å·ç»“æ„...")

        sections = []
        current_paper = None
        current_type = None
        current_content = []

        for page in pages_text:
            lines = page['text'].split('\n')

            for line in lines:
                line = line.strip()
                if not line:
                    continue

                # æ£€æµ‹æ˜¯å¦æ˜¯æ–°çš„"å·"
                paper_match = self.paper_pattern.search(line)
                if paper_match and line.startswith('å·'):
                    # ä¿å­˜ä¹‹å‰çš„section
                    if current_paper and current_content:
                        sections.append({
                            'paper': current_paper,
                            'type': current_type or 'Unknown',
                            'content': '\n'.join(current_content)
                        })

                    current_paper = f"å·{paper_match.group(1)}"
                    current_type = None
                    current_content = []
                    continue

                # æ£€æµ‹æ˜¯å¦æ˜¯æ–°çš„é¢˜å‹
                type_match = self.type_pattern.match(line)
                if type_match:
                    # ä¿å­˜ä¹‹å‰çš„section
                    if current_paper and current_content:
                        sections.append({
                            'paper': current_paper,
                            'type': current_type or 'Unknown',
                            'content': '\n'.join(current_content)
                        })

                    current_type = type_match.group(1)
                    current_content = []
                    continue

                # æ”¶é›†é¢˜ç›®å†…å®¹
                if current_paper:
                    current_content.append(line)

        # ä¿å­˜æœ€åä¸€ä¸ªsection
        if current_paper and current_content:
            sections.append({
                'paper': current_paper,
                'type': current_type or 'Unknown',
                'content': '\n'.join(current_content)
            })

        # æ‰“å°è¯†åˆ«ç»“æœ
        paper_section_count = {}
        for sec in sections:
            if sec['paper'] not in paper_section_count:
                paper_section_count[sec['paper']] = 0
            paper_section_count[sec['paper']] += 1

        for paper, count in sorted(paper_section_count.items()):
            print(f"   {paper}: {count} ä¸ªé¢˜å‹éƒ¨åˆ†")

        return sections

    def extract_questions_from_section(self, section: Dict) -> List[Dict]:
        """
        ä»sectionä¸­æå–é¢˜ç›®

        Args:
            section: è¯•å·éƒ¨åˆ†

        Returns:
            List[Dict]: é¢˜ç›®åˆ—è¡¨
        """
        questions = []
        content = section['content']

        for pattern in self.config.QUESTION_PATTERNS:
            matches = re.finditer(pattern, content, re.MULTILINE)

            for match in matches:
                q_num = match.group(1)
                q_content = match.group(2).strip()

                # æ¸…ç†å†…å®¹
                q_content = re.sub(r'\s+', ' ', q_content)
                q_content = q_content.strip()

                # è¿‡æ»¤å¤ªçŸ­æˆ–æ— æ•ˆå†…å®¹
                if len(q_content) < self.config.min_content_length:
                    continue

                # è¿‡æ»¤çº¯æ•°å­—æˆ–å­—æ¯
                if re.match(r'^[\dA-D\s()]+$', q_content):
                    continue

                questions.append({
                    'Paper_ID': section['paper'],
                    'Question_Type': section['type'],
                    'Question_Number': q_num,
                    'Content': q_content[:self.config.max_content_length]
                })

            if questions:
                break

        return questions

    def extract_questions(self, sections: List[Dict]) -> List[Dict]:
        """
        ä»æ‰€æœ‰éƒ¨åˆ†æå–é¢˜ç›®

        Args:
            sections: è¯•å·éƒ¨åˆ†åˆ—è¡¨

        Returns:
            List[Dict]: æ‰€æœ‰é¢˜ç›®åˆ—è¡¨
        """
        print("\nğŸ·ï¸  æ­¥éª¤3: æå–é¢˜ç›®...")

        all_questions = []
        for section in sections:
            questions = self.extract_questions_from_section(section)
            all_questions.extend(questions)

        print(f"   âœ… å…±æå– {len(all_questions)} é“é¢˜ç›®")

        # æŒ‰åˆ†å·ç»Ÿè®¡
        paper_stats = {}
        for q in all_questions:
            p = q['Paper_ID']
            paper_stats[p] = paper_stats.get(p, 0) + 1

        print(f"\n   å„åˆ†å·é¢˜ç›®æ•°:")
        for paper, count in sorted(paper_stats.items()):
            print(f"      {paper}: {count} é“")

        return all_questions
